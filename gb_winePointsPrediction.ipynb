{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "\n",
    "    \n",
    "# READ THE CSV FILE         \n",
    "\n",
    "'''-------------- file_to_lst ---------------------------\n",
    "IN: the csv filename where the data are stored\n",
    "    features_INDEX: list of the indexes of the features \n",
    "    we want to keep \n",
    "RESULT: the data in a list\n",
    "-------------------------------------------------------'''\n",
    "\n",
    "def file_to_lst(filename, features):\n",
    "    file = open(filename, \"r\")\n",
    "    reader = csv.reader(file, delimiter=\",\")\n",
    "    \n",
    "    # INDEX DEFINITION \n",
    "    name_columns = next(reader)\n",
    "\n",
    "    INDEX_POINTS = name_columns.index(\"points\") \n",
    "    \n",
    "    features_INDEX = []\n",
    "    for i, feature in enumerate(features):\n",
    "        features_INDEX.append(name_columns.index(feature))\n",
    "        \n",
    "        \n",
    "    collected_data = []\n",
    "\n",
    "    # NOT USED HERE: ID (0), designation (2), title (8)\n",
    "    \n",
    "    for r in reader:\n",
    "        collected_data.append([])\n",
    "        collected_data[-1].append(ast.literal_eval(r[INDEX_POINTS]))\n",
    "        for i, index in enumerate(features_INDEX):\n",
    "            feature_value = ast.literal_eval(r[index])\n",
    "            try: \n",
    "                for j, value in enumerate(feature_value):\n",
    "                    collected_data[-1].append(value)\n",
    "            except TypeError:\n",
    "                collected_data[-1].append(feature_value)\n",
    "                \n",
    "            \n",
    "    file.close()\n",
    "    return collected_data\n",
    "\n",
    "######################################\n",
    "#              CALL\n",
    "######################################\n",
    "\n",
    "#filename = \"DF_version2Francesco.csv\"\n",
    "filename = \"DF_version2_withDesc.csv\"\n",
    "#filename = \"DF_version2.csv\"\n",
    "\n",
    "features1 = [\"price\", \"country\", \"vintage\"] #\"country\", \"province\", \"region_1\", \"variety\", top1_desc, top2_desc, top3_desc\n",
    "collected_data1 = file_to_lst(filename, features1)\n",
    "\n",
    "features2 = [\"taster_name\"]\n",
    "collected_data2 = file_to_lst(filename, features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2011]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(collected_data1[1])\n",
    "print(len(collected_data1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "\n",
    "# FORMAT THE DATA (from list to np-array)\n",
    "                               \n",
    "'''-------------------- format_data -------------------------\n",
    "IN: collected_data: list of a list reflecting the data (where\n",
    "the last element is what it has to be predicted)\n",
    "RESULT: numpy array to be used for training/testing a model\n",
    " ----------------------------------------------------------'''\n",
    "\n",
    "\n",
    "def format_data(collected_data):\n",
    "    size = len(collected_data[0]) -1\n",
    "    x = np.zeros((len(collected_data), size), dtype=np.float)\n",
    "    y = np.zeros((x.shape[0],), dtype=np.float)\n",
    "\n",
    "    for k, data in enumerate(collected_data):\n",
    "\n",
    "        x[k] = data[1:]\n",
    "        y[k] = data[0]\n",
    "\n",
    "    return x, y                               \n",
    "                               \n",
    "\n",
    "    \n",
    "# SPLIT THE DATASET INTO A TRAINING AND A TESTING SET \n",
    "def DS_builder(collected_data, p=0.75):\n",
    "\n",
    "    # Shuffle the data to reduce the bias\n",
    "    random.shuffle(collected_data)\n",
    "    \n",
    "    data_len = len(collected_data)\n",
    "    testing_set = []\n",
    "    learning_set = []\n",
    "    \n",
    "    # ------ We go trough all the data ------\n",
    "    for count, data in enumerate(collected_data):\n",
    "            if count / data_len < p:\n",
    "                learning_set.append(data)\n",
    "            else:\n",
    "                testing_set.append(data)\n",
    "\n",
    "    xls, yls = format_data(learning_set)\n",
    "    xts, yts = format_data(testing_set)\n",
    "    ds = [xls, yls, xts, yts]\n",
    "    \n",
    "    return ds\n",
    "\n",
    "INDEX_XLS = 0\n",
    "INDEX_YLS = 1 \n",
    "INDEX_XTS = 2\n",
    "INDEX_YTS = 3\n",
    "\n",
    "######################################\n",
    "#              CALL\n",
    "######################################\n",
    "\n",
    "ds1 = DS_builder(collected_data1)\n",
    "ds2 = DS_builder(collected_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# STILL TODO: parameter tuning \n",
    "########################################\n",
    "\n",
    "\n",
    "# DEFINE YOUR MODEL AND TRAIN IT\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR \n",
    "\n",
    "algorithm = \"LinearRegression\"\n",
    "\n",
    "\n",
    "# ------------ Management of the learning algorithm ----------------------\n",
    "if algorithm == \"LinearRegression\":\n",
    "    estimator1 = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "    estimator2 = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(ds2[INDEX_XLS], ds2[INDEX_YLS])\n",
    "\n",
    "elif algorithm == \"LogisticRegression\":\n",
    "    estimator1 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "    estimator2 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None).fit(ds2[INDEX_XLS], ds2[INDEX_YLS])\n",
    "\n",
    "elif algorithm == \"DecisionTreeRegressor\":\n",
    "    estimator1 = DecisionTreeRegressor(max_depth=5).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "    estimator2 = DecisionTreeRegressor(max_depth=5).fit(ds2[INDEX_XLS], ds2[INDEX_YLS])\n",
    "\n",
    "elif algorithm == \"SVR\":\n",
    "    svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "    svr_lin = SVR(kernel='linear', C=1e3).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2).fit(ds1[INDEX_XLS], ds1[INDEX_YLS])\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 with the features: ['price'] and the algorithm LinearRegression\n",
      "\n",
      "Test 2 with the features: ['taster_name'] and the algorithm LinearRegression\n",
      "\n",
      "The explained variance score is: 0.15151736442080888\n",
      "The explained variance score is: 0.0\n",
      "\n",
      "The mean absolute error is: 2.27183560095645\n",
      "The mean absolute error is: 2.536924378287522\n",
      "\n",
      "The mean squared error is: 2.27183560095645\n",
      "The mean squared error is: 2.536924378287522\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################\n",
    "# STILL TODO: Interpretation of the computed accuracy (and maybe test with other metrics)\n",
    "###########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "with_prob = False\n",
    "\n",
    "# MAKE PREDICTION \n",
    "if with_prob:\n",
    "    predicted_points1 = estimator1.predict_proba(ds1[INDEX_XTS])\n",
    "else: \n",
    "    predicted_points1 = estimator1.predict(ds1[INDEX_XTS])\n",
    "    predicted_points2 = estimator2.predict(ds2[INDEX_XTS])\n",
    "\n",
    "    \n",
    "# COMPUTE ACCURACY \n",
    "print(\"Test 1 with the features: \" + str(features1) + \" and the algorithm \" + algorithm + \"\\n\")\n",
    "print(\"Test 2 with the features: \" + str(features2) + \" and the algorithm \" + algorithm + \"\\n\")\n",
    "\n",
    "evs1 = explained_variance_score(ds1[INDEX_YTS], predicted_points1)\n",
    "print(\"The explained variance score is: \" + str(evs1))\n",
    "\n",
    "evs2 = explained_variance_score(ds2[INDEX_YTS], predicted_points2)\n",
    "print(\"The explained variance score is: \" + str(evs2) + \"\\n\")\n",
    "\n",
    "mae1 = mean_absolute_error(ds1[INDEX_YTS], predicted_points1) # The best value is 0 \n",
    "print(\"The mean absolute error is: \" + str(mae1))\n",
    "\n",
    "mae2 = mean_absolute_error(ds2[INDEX_YTS], predicted_points2) # The best value is 0 \n",
    "print(\"The mean absolute error is: \" + str(mae2) + \"\\n\")\n",
    "\n",
    "mse1 = mean_squared_error(ds1[INDEX_YTS], predicted_points1) # The best value is 0 \n",
    "print(\"The mean squared error is: \" + str(mae1))\n",
    "\n",
    "mse2 = mean_squared_error(ds2[INDEX_YTS], predicted_points2) # The best value is 0 \n",
    "print(\"The mean squared error is: \" + str(mae2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.12211533 87.94471637 88.88182983 ... 89.12211533 88.13694477\n",
      " 88.28111607]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_points1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
