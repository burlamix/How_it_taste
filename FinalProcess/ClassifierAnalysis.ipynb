{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_base = pd.read_csv(\"Our_dataset/StemmedWord2vecTop3_parsed_weather_labeled.csv\", index_col=0) \n",
    "wine_base = wine_base.reset_index()\n",
    "wine_base= wine_base[pd.notnull(wine_base['description'])]\n",
    "wine_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "sns.distplot(wine_base[\"points\"],hist=True,bins = 20,hist_kws={'edgecolor':'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE NUMBER OF BINS = classes to be predicted (must be executed so that Y is the same for every execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = wine_base['points'].copy()\n",
    "#DECIDE NUMBER OF BINS \n",
    "#nbins  = 4\n",
    "#labels=[\"low\",\"medium\",\"high\",\"very_high\"]\n",
    "#nbins = 5\n",
    "#labels=[\"very_low\", \"low\", \"medium\",\"high\",\"very_high\"]\n",
    "#bin identici \n",
    "#Y,bins = pd.cut(Y,nbins,labels=labels,retbins=True,include_lowest=True,right=True)\n",
    "#quartile\n",
    "nbins  = 3\n",
    "labels=[\"low\",\"medium\",\"high\"]\n",
    "Y,bins = pd.qcut(Y,nbins,labels=labels,retbins=True)   #uses quartiles and statistic stuff\n",
    "values = Y.tolist()  \n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the binning result\n",
    "fig, ax = plt.subplots(figsize = (12, 5))\n",
    "for i in range(1,len(bins)-1):\n",
    "\n",
    "    if i == 1:\n",
    "        a = wine_base[wine_base[\"points\"] <= bins[i]]\n",
    "        n =  bins[i]-80\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+n\n",
    "    if i == len(bins)-1:\n",
    "        a = wine_base[wine_base[\"points\"] > bins[i]]\n",
    "        n = 100 - bins[i]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "        g =+ n\n",
    "    else:\n",
    "        n = bins[i+1] - bins[i]\n",
    "        g =+n\n",
    "        a = wine_base[(wine_base[\"points\"] > bins[i]) & (wine_base[\"points\"] <= bins[i+1])]\n",
    "        sns.distplot(a[\"points\"],hist_kws={\"width\": 0.5,'edgecolor':'black'},kde=False)\n",
    "ax.set(xticks=wine_base[\"points\"].unique())\n",
    "print(g)\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = [\"price\",'vintage', 'country', 'province', 'region_1', 'taster_name', 'variety','winery']\n",
    "word = [\"word_count\"]\n",
    "tfGroup = ['tf_grouped_1','tf_grouped_2', 'tf_grouped_3']\n",
    "tfIdfGroup = ['tfIdf_grouped_1', 'tfIdf_grouped_2', 'tfIdf_grouped_3']\n",
    "tfFull = ['tf_fullData_1', 'tf_fullData_2', 'tf_fullData_3',]\n",
    "tfIdfFull = ['tfIdf_fullData_1', 'tfIdf_fullData_2', 'tfIdf_fullData_3']\n",
    "#weather = ['pr_5', 'pr_6', 'pr_7', 'pr_8', 'pr_9', 'tas_5', 'tas_6', 'tas_7', 'tas_8', 'tas_9']# don't really care bcs 0 improvements\n",
    "word2vec = ['similarityTop3WinesByVariety']\n",
    "features = basic + word + tfGroup + word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMMY CLASSIFIER = BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = wine_base.loc[:,features]\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "classifier = DummyClassifier(\"stratified\")\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER WITHOUT SPARSE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decTree(features, depth, data):\n",
    "    X = data.loc[:,features]\n",
    "    test_size = 0.30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)  \n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "\n",
    "    #get feature importances\n",
    "    lista = []\n",
    "    for name, importance in zip(features, classifier.feature_importances_):\n",
    "        lista.append([name, importance])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred,labels=labels)\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"price\",\"vintage\"] #basic + word2vec + word_count...\n",
    "depth = 4\n",
    "clf = decTree(features,depth,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "import os\n",
    "import sys\n",
    "def conda_fix(graph):\n",
    "        path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "        paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "        paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "        graph.set_graphviz_executables(paths)\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=features,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier using sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseMatrixRep(features,depth,data,test_size):\n",
    "    X = data.loc[:,features+[\"description\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    #compute countvectorizer\n",
    "    vect = CountVectorizer(min_df=5)\n",
    "    vect.fit(X_train['description'])\n",
    "    print(\"vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "    X_train_vectored_cv = vect.transform(X_train['description'])\n",
    "    X_train_final = X_train_vectored_cv\n",
    "    for feature in features:\n",
    "        X_train_final = hstack((X_train_final,np.array(X_train[feature])[:,None]))\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train_final, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train_final)\n",
    "    X_test_final = vect.transform(X_test['description'])\n",
    "    for feature in features:\n",
    "        X_test_final = hstack((X_test_final,np.array(X_test[feature])[:,None]))\n",
    "\n",
    "    y_test_pred = clf.predict(X_test_final)\n",
    "    print(classification_report(y_test, y_test_pred, target_names=labels))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the input and compute\n",
    "\n",
    "features = [\"price\"] #basic #+ word + tfGroup + word2vec\n",
    "depth = 3\n",
    "test_size = 0.30\n",
    "clf = sparseMatrixRep(features,depth,wine_base,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show me the tree\n",
    "##### Graphviz sucks, you need to check if it's installed and it may give you problems anyway, the code below fixed it for me\"\n",
    "#### be sure that you have the package installed\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "\n",
    "def conda_fix(graph):\n",
    "    path = os.path.join(sys.base_exec_prefix, \"Library\", \"bin\", \"graphviz\")\n",
    "    paths = (\"dot\", \"twopi\", \"neato\", \"circo\", \"fdp\")\n",
    "    paths = {p: os.path.join(path, \"{}.exe\".format(p)) for p in paths}\n",
    "    graph.set_graphviz_executables(paths)\n",
    "    \n",
    "dot_data = tree.export_graphviz(clf, out_file=None,   \n",
    "                             class_names=labels,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "conda_fix(graph)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with combinations and get results dataframe (no countvect working on this as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with every test combination you put\n",
    "def testToDataFrame(algorithm,combination,Y,allfeats,dataset):\n",
    "    test_size = 0.30 \n",
    "    cols = [\"algorithm\",\"input\",\"precision\",\"accuracy\",\"depth\"]\n",
    "    for lab in labels:\n",
    "        cols.append(lab +\"_prec\")\n",
    "        cols.append(lab +\"_recall\")\n",
    "        cols.append(lab +\"_f1\")\n",
    "        cols.append(lab +\"_support\")\n",
    "    for el in allfeats: #controlla che allfeats vada bene, amgari fotte con l'ordine\n",
    "        cols.append(\"feat_\"+el)\n",
    "    results = pd.DataFrame()\n",
    "    row = 0\n",
    "    comb = 0\n",
    "    for el in combination[\"args\"]: \n",
    "        for depth in combination[\"depth\"]:\n",
    "            row = row + 1\n",
    "            X = dataset.loc[:,el]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "            if algorithm == \"decTree\":\n",
    "                classifier = DecisionTreeClassifier(max_depth=depth)\n",
    "            else:\n",
    "                classifier = RandomForestClassifier(max_depth=depth,n_estimators = estimators)\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict(X_test)  \n",
    "            acc = accuracy_score(y_test,y_pred)\n",
    "            weightedPrec = precision_score(y_test,y_pred,average=\"weighted\")        \n",
    "            data = [algorithm,el,weightedPrec,acc,depth]\n",
    "            precision,recall,fscore,support = precision_recall_fscore_support(y_test, y_pred)\n",
    "            for i in range(0,len(labels)):\n",
    "                data.append(precision[i])\n",
    "                data.append(recall[i])\n",
    "                data.append(fscore[i])\n",
    "                data.append(support[i])\n",
    "            #for lab in labels:\n",
    "            \n",
    "             #   data.append(rep[lab].precision)     #ORDER IS VERY IMPORTANT\n",
    "              #  data.append(rep[lab].recall)\n",
    "               # data.append(rep[lab].f1-score)\n",
    "                #data.append(rep[lab].support)\n",
    "            temp = {}\n",
    "            c = zip(el,classifier.feature_importances_)\n",
    "            for name,importance in c:\n",
    "                temp[name] = importance\n",
    "            for feat in allfeats:\n",
    "                if feat not in el:\n",
    "                    data.append(100) #100 is an impossible value not to be taken into account\n",
    "                else:\n",
    "                    data.append(temp[feat])\n",
    "            df2 = pd.DataFrame([data],columns=cols)\n",
    "            results = results.append(df2,ignore_index=True)\n",
    "        comb = comb + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [[\"price\"],[\"price\",\"word_count\"],basic,basic+tfGroup, basic+word2vec,basic+word2vec+tfGroup,word2vec,tfGroup,word2vec+tfGroup]\n",
    "allfeatures = basic + word + word2vec + tfGroup \n",
    "decTreeCombinations = {\"depth\":[2,3,4,5],\"args\":args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = testToDataFrame(\"decTree\",decTreeCombinations,Y,allfeatures,wine_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values([\"precision\",'depth'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[17]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
